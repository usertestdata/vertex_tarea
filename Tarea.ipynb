{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVctDuFzhuoO"
      },
      "source": [
        "\n",
        "## Tarea 1 Vertex - Michael H."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependecias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9rW-VT5hm2e",
        "outputId": "8184a475-7c64-4c65-b14f-4ac1aa266997"
      },
      "outputs": [],
      "source": [
        "!pip install kfp google-cloud-aiplatform==1.18.1 tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -U google-cloud-aiplatform \"shapely<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importar y variables de entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwhsQSgviSov"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qnz1_DWk4V4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# VARIABLES DE GCP\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] =  ''\n",
        "PIPELINE_ID = os.getenv(\"PIPELINE_CONFIG_ID\")\n",
        "PIPELINE_DISPLAY_NAME = os.getenv(\"PIPELINE_DISPLAY_NAME\", \"mypipeline\")\n",
        "PIPELINE_COMPILE_FILE = os.getenv(\"PIPELINE_COMPILE_FILE\", './pipeline_compile.json') \n",
        "PIPELINE_SERVICE_ACCOUNT = os.getenv(\"PIPELINE_SERVICE_ACCOUNT\", \"\") \n",
        "PIPELINE_PROJECT_ID = os.getenv(\"PIPELINE_PROJECT_ID\", \"\") \n",
        "PIPELINE_REGION = os.getenv(\"PIPELINE_REGION\", \"\") \n",
        "PIPELINE_BUCKET = os.getenv(\"PIPELINE_BUCKET\", \"\")\n",
        "PIPELINE_PATH_ROOT = os.getenv(\"PIPELINE_PATH_ROOT\", \"locale_root\")\n",
        "SERVICE_ACCOUNT = ''\n",
        "\n",
        "\n",
        "PROJECT_ID = PIPELINE_PROJECT_ID\n",
        "BUCKET_NAME = f\"gs://{PIPELINE_BUCKET}\" \n",
        "REGION = PIPELINE_REGION\n",
        "PIPELINE_ROOT = os.path.join(BUCKET_NAME, PIPELINE_PATH_ROOT)\n",
        "\n",
        "\n",
        "# VARIABLES PARA PIPELINE VERTEX\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "DISPLAY_NAME = 'pipeline-houseprice-job{}'.format(TIMESTAMP)\n",
        "PIPELINE_PARAMS = {\"project_id\": PROJECT_ID,\n",
        "                   \"dataset_location\": REGION,\n",
        "                }\n",
        "TEMPLATE_PATH = \"housing_pipeline.json\"\n",
        "PIPELINE_NAME = \"housing_price\"\n",
        "JOBID = f\"training-pipeline-{TIMESTAMP}\"\n",
        "ENABLE_CACHING = False\n",
        "\n",
        "\n",
        "#VARIABLES DE DEPENDECIAS\n",
        "IMAGE_NAME = \"training\"\n",
        "BASE_IMAGE = \"gcr.io/cloud-aiplatform/prediction/sklearn-cpu.0-23:latest\"\n",
        "PANDAS = \"pandas==1.3.2\"\n",
        "SKLEARN = \"scikit-learn==1.0.2\"\n",
        "NUMPY = \"numpy==1.21.6\"\n",
        "TENSORFLOW = \"tensorflow==2.16.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE5An7EHlUoD"
      },
      "outputs": [],
      "source": [
        "import google.cloud.aiplatform as aiplatform\n",
        "\n",
        "from kfp.v2 import dsl, compiler\n",
        "\n",
        "from kfp.v2.dsl import (component, Input, Model, Output, Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COMPONENTES - VERTEX IA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQJA9i08m3F6"
      },
      "source": [
        "# LOAD DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " El primer componente obtiene datos de Cloud Storage para generar un DataFrame de pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJRulPzule9B"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "    base_image=BASE_IMAGE,\n",
        "    output_component_file=\"get_data.yaml\"\n",
        "    , packages_to_install=[PANDAS]\n",
        ")\n",
        "\n",
        "def get_houseprice_data(\n",
        "    filepath: str,\n",
        "    dataset: Output[Dataset]\n",
        "):\n",
        "\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(filepath + \"/BostonHousing.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihxOjtlXnXPY"
      },
      "source": [
        "# SPLIT DATA AND TRAIN MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este componente realiza el split de la data para el entrenamiento y test para posteriormente hacer la implementación de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gLpvQGcvnVlY",
        "outputId": "10fbc4b9-a031-4d7a-970e-d928dbafff0d"
      },
      "outputs": [],
      "source": [
        "@component(base_image=BASE_IMAGE, packages_to_install=[TENSORFLOW],\n",
        "            output_component_file=\"model_training.yaml\")\n",
        "def train_houseprice(\n",
        "    dataset_in: Input[Dataset],\n",
        "    model: Output[Model]\n",
        "):\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "    def last_model():\n",
        "        # create model\n",
        "        model = Sequential()\n",
        "        model.add(Dense(20, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
        "        model.add(Dense(13, kernel_initializer='normal', activation='relu'))\n",
        "        model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "        model.add(Dense(1, kernel_initializer='normal'))\n",
        "        # Compile model\n",
        "        model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    X = dataset_in[:,0:13]\n",
        "    Y = dataset_in[:,13]\n",
        "\n",
        "\n",
        "    model = last_model()\n",
        "\n",
        "    X_train = X[:450]\n",
        "    Y_train = Y[:450]\n",
        "    X_val = X[451:500]\n",
        "    Y_val = Y[451:500]\n",
        "\n",
        "    model.fit(X_train, Y_train, epochs=100, batch_size=5,\n",
        "                     validation_data=(X_val, Y_val), verbose=1)\n",
        "\n",
        "    model.save('housing.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB-NVyuJnodA"
      },
      "source": [
        "# UPLOAD MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se encarga de subir el modelo de red neuronal a Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmHTkbDRnddr"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "    base_image=BASE_IMAGE,\n",
        "    install_kfp_package=False,\n",
        "    output_component_file=\"model.yaml\",\n",
        ")\n",
        "def upload_houseprice(\n",
        "        serving_container_image_uri: str,\n",
        "        display_name: str,\n",
        "        gcp_project: str,\n",
        "        gcp_region: str,\n",
        "        model: Input[Model],\n",
        "        uploaded_model:Output[Model],\n",
        "        vertex_model: Output[Model]\n",
        "):\n",
        "    from google.cloud import aiplatform as vertex_ai\n",
        "    from pathlib import Path\n",
        "\n",
        "\n",
        "    listed_model = vertex_ai.Model.list(\n",
        "        filter='display_name=\"{}\"'.format(display_name),\n",
        "        project=gcp_project,\n",
        "        location=gcp_region)\n",
        "\n",
        "    listed_model = vertex_ai.Model.list(\n",
        "        filter='display_name=\"{}\"'.format(display_name),\n",
        "        project=gcp_project,\n",
        "        location=gcp_region,\n",
        "        )\n",
        "\n",
        "    if len(listed_model) > 0:\n",
        "        model_version = listed_model[0] # most recently created\n",
        "        model_upload = vertex_ai.Model.upload(\n",
        "            display_name=display_name,\n",
        "            parent_model=model_version.resource_name,\n",
        "            artifact_uri=str(Path(model.path).parent),\n",
        "            serving_container_image_uri=serving_container_image_uri,\n",
        "            location=gcp_region,\n",
        "            serving_container_predict_route=\"/predict\",\n",
        "            serving_container_health_route=\"/health\"\n",
        "        )\n",
        "    else:\n",
        "        model_upload = vertex_ai.Model.upload(\n",
        "            display_name=display_name,\n",
        "            artifact_uri=str(Path(model.path).parent),\n",
        "            serving_container_image_uri=serving_container_image_uri,\n",
        "            location=gcp_region,\n",
        "            serving_container_predict_route=\"/predict\",\n",
        "            serving_container_health_route=\"/health\"\n",
        "        )\n",
        "\n",
        "    uploaded_model = model_upload\n",
        "     # Save data to the output params\n",
        "    vertex_model.uri = model_upload.resource_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXVoKVqInv0m"
      },
      "source": [
        "# ENDPOINT CREATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Despliega el modelo, generado una url para el endpoints para ser consumido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjnjI7c8nsWs"
      },
      "outputs": [],
      "source": [
        "@component(\n",
        "    base_image=BASE_IMAGE,\n",
        "    install_kfp_package=False,\n",
        "    output_component_file=\"model_deployment.yaml\",\n",
        ")\n",
        "def deploy_houseprice(\n",
        "        display_name: str,\n",
        "        model_endpoint: str,\n",
        "        gcp_project: str,\n",
        "        gcp_region: str,\n",
        "        vertex_model: Input[Model],\n",
        "        uploaded_model: Input[Model],\n",
        "        vertex_endpoint: Output[Model]\n",
        "):\n",
        "    from google.cloud import aiplatform as vertex_ai\n",
        "    from pathlib import Path\n",
        "\n",
        "    endpoints = vertex_ai.Endpoint.list(\n",
        "        filter='display_name=\"{}\"'.format(model_endpoint),\n",
        "        order_by='create_time desc',\n",
        "        project=gcp_project,\n",
        "        location=gcp_region,\n",
        "        )\n",
        "    if len(endpoints) > 0:\n",
        "        endpoint = endpoints[0] # most recently created\n",
        "    else:\n",
        "        endpoint = vertex_ai.Endpoint.create(\n",
        "            display_name=model_endpoint,\n",
        "            project=gcp_project,\n",
        "            location=gcp_region\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Deploys trained model to Vertex AI Endpoint\n",
        "    model_deploy = uploaded_model.deploy(\n",
        "        machine_type='n1-standard-2',\n",
        "        endpoint=endpoint,\n",
        "        traffic_split={\"0\": 100},\n",
        "        deployed_model_display_name=display_name,\n",
        "    )\n",
        "\n",
        "    # Save data to the output params\n",
        "    vertex_endpoint.uri = model_deploy.resource_name\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hAEaZNn1M3"
      },
      "source": [
        "## Crear Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente se crea el pipeline que contiene los componentes ya mencionados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0MOdr8XWnx9X",
        "outputId": "ba6aac7e-6571-4731-a987-b6ca8374710f"
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    name=\"pipeline-houseprice\"   \n",
        ")\n",
        "\n",
        "\n",
        "def pipeline(\n",
        "    data_filepath: str = f\"{BUCKET_NAME}/data\",\n",
        "    project: str = PROJECT_ID,\n",
        "    region: str = REGION,\n",
        "    display_name: str = DISPLAY_NAME,\n",
        "    serving_container_image_uri: str = BASE_IMAGE\n",
        "):\n",
        "\n",
        "    data_op = get_houseprice_data(data_filepath)\n",
        "    data_preprocess_op = train_houseprice(data_op.outputs[\"dataset\"])\n",
        "\n",
        "    upload_model_op = upload_houseprice(\n",
        "        model = data_preprocess_op.outputs['model'],\n",
        "        gcp_project = PROJECT_ID,\n",
        "        gcp_region = REGION,\n",
        "        serving_container_image_uri = BASE_IMAGE,\n",
        "        display_name = \"houseprice\",\n",
        "    )\n",
        "\n",
        "\n",
        "    deploy_model_op = deploy_houseprice(\n",
        "        uploaded_model=upload_model_op.outputs['uploaded_model'],\n",
        "        vertex_model= upload_model_op.outputs['vertex_model'],\n",
        "        gcp_project = PROJECT_ID,\n",
        "        gcp_region = REGION,\n",
        "        display_name = \"houseprice\",\n",
        "        model_endpoint = \"houseprice_endpoint\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5TQITn3oupy"
      },
      "source": [
        "## Compilar y correr Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación se realiza la ejecución del pipeline en GCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtafzwP9oO4-"
      },
      "outputs": [],
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline, package_path=TEMPLATE_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "3yhhc0IbozGO",
        "outputId": "b9f8475e-9a90-4107-bd39-36a5101230af"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TK9cx3BIpWLp",
        "outputId": "86459a90-0c8f-4e5e-d223-68ca6f2ed8de"
      },
      "outputs": [],
      "source": [
        "# RUN THE PIPELINE\n",
        "\n",
        "pipeline_ = aiplatform.pipeline_jobs.PipelineJob(\n",
        "    enable_caching=ENABLE_CACHING,\n",
        "    display_name=PIPELINE_NAME,\n",
        "    template_path=TEMPLATE_PATH,\n",
        "    job_id=JOBID)\n",
        "\n",
        "pipeline_.submit(SERVICE_ACCOUNT)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
